# MIP-004: A Hashing Standard for Data Integrity

## Author
Patrick Tobler, Albina Nikiforova

## Title
MIP-004: A Hashing Standard for Data Integrity

## Abstract
This proposal introduces a foundational standard for creating a deterministic, verifiable hash of input data payloads within the Masumi network. We propose a specific three-step process: serializing the data payload using the JSON Canonicalization Scheme (JCS, RFC 8785), prepending a unique `identifier_from_purchaser`, and hashing the combined string using SHA-256. Adopting this standard is crucial for ensuring data integrity, enabling non-repudiation, and fostering interoperability between all participants in the Masumi ecosystem.

## Problem Statement
For the Masumi network to function as a trust-minimized system, there must be a standard way to create a unique and tamper-proof fingerprint for data, particularly for the inputs provided to AI agents. Without a formally defined hashing standard, the network would face significant challenges:

-   **Lack of Verifiability:** Users would have no way to prove exactly what input data they submitted to an agent service, making disputes impossible to resolve.
-   **Inconsistent Implementations:** Different services, potentially written in different programming languages, might implement their own proprietary hashing methods. This would create a fragmented ecosystem where hashes from one service are incompatible with another.
-   **Data Integrity Risks:** There would be no reliable method to confirm that the data an agent receives is identical to the data the user sent, opening the door to accidental corruption or man-in-the-middle modifications.

A clear, deterministic, and universally adopted hashing standard is a prerequisite for a secure and functional decentralized AI network.

## Solution
We propose the adoption of a formal, three-step hashing standard for all input data payloads that require a cryptographic fingerprint. This standard is designed to be simple, robust, and based on established open standards.

## Technical Specification
The proposed hashing process shall generate a unique hash from two pieces of information: an `input_data` dictionary and an `identifier_from_purchaser` string.

### Step 1: Canonical JSON Serialization
To ensure a deterministic representation, the `input_data` dictionary must be serialized into a byte string. This serialization **must** conform to the **JSON Canonicalization Scheme (JCS) as specified in RFC 8785**. This process guarantees that any two JSON objects with the same content, regardless of key order or whitespace, will produce the exact same byte-for-byte output. The resulting bytes should be interpreted as a UTF-8 string for the next step.

### Step 2: Pre-image Construction via Concatenation
The final string to be hashed (the pre-image) shall be constructed by prepending the `identifier_from_purchaser` string directly to the canonical JSON string generated in Step 1.

The formula is:
`string_to_hash = identifier_from_purchaser + canonical_json_string`

### Step 3: Hashing Algorithm
The constructed `string_to_hash` from Step 2 must be encoded into bytes using the UTF-8 encoding. The resulting bytes must then be hashed using the **SHA-256** algorithm. The final hash digest should be presented as a **lowercase hexadecimal string**.

### Proposed Implementation
The following Python code serves as a reference implementation demonstrating how this specification would be put into practice.

```python
import hashlib
import canonicaljson
import logging as logger

def create_masumi_hash(input_data: dict, identifier_from_purchaser: str) -> str:
        """
        Creates a hash based on the Masumi Standard Hashing Proposal (MIP-004).
        """

        # Step 1: Serialize the data using JCS (RFC 8785).
        canonical_json_string = canonicaljson.encode_canonical_json(input_data).decode('utf-8')
        logger.debug(f"Canonical Input JSON: {canonical_json_string}")

        # Step 2: Construct the pre-image by prepending the purchaser identifier.
        string_to_hash = identifier_from_purchaser + canonical_json_string
        logger.debug(f"Pre-image for hashing: {string_to_hash}")

        # Step 3: Encode to UTF-8 and hash with SHA-256.
        return hashlib.sha256(string_to_hash.encode('utf-8')).hexdigest()
```

## Rationale
This proposed solution is chosen for the following reasons:

-   **Based on Open Standards:** It leverages two widely adopted and vetted standards: SHA-256 for cryptographic security and RFC 8785 for deterministic serialization. This reduces risk and simplifies implementation.
-   **Simplicity and Clarity:** The process is straightforward and easy for developers to understand and implement across different programming languages, fostering wide adoption.
-   **Deterministic by Design:** The use of canonical JSON is critical for ensuring that any participant in the network can reliably reproduce a hash given the same initial data.

## Risks and Considerations
-   **Concatenation Ambiguity:** The direct string concatenation in Step 2, while simple, creates a potential ambiguity. A malicious actor could craft an `identifier_from_purchaser` and `input_data` to intentionally cause a hash collision with a legitimate, different set of inputs. For example, `(id="userA", json="123{}")` and `(id="userA123", json="{}")` would both produce the string `"userA123{}"` to be hashed. While this risk is noted, the simplicity of this initial standard is prioritized for bootstrap adoption. This can be addressed in a future MIP if it becomes a practical concern.
-   **Limited Extensibility:** The current proposal does not include a versioning or a flexible structure for adding more contextual data to the hash (e.g., a timestamp or nonce). Future extensions would require a new MIP.
-   **Implementation Correctness:** The security of the entire system relies on all parties using a correct and compliant RFC 8785 library. An incorrect implementation would lead to hash mismatches and system failure.